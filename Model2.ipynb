{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78yMdB9jkKqf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "lEIb64zHkUA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=2,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(256*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "qJbSp-Jqkg8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet(BasicBlock, [2,2,2,2])"
      ],
      "metadata": {
        "id": "BRtnAy9ikj-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "TwIB7xdYT3y8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device to use\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Instantiate ResNet model\n",
        "model = model.to(device)\n",
        "\n",
        "# Generate example input data\n",
        "inputs = torch.randn(1, 3, 32, 32).to(device)\n",
        "\n",
        "# Print model summary\n",
        "summary(model, input_size=(3, 32, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5N-fX7VkmLM",
        "outputId": "7b791be1-619f-44e7-9365-6a0dc550e8a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 33, 33]             768\n",
            "       BatchNorm2d-2           [-1, 64, 33, 33]             128\n",
            "            Conv2d-3           [-1, 32, 33, 33]          18,432\n",
            "       BatchNorm2d-4           [-1, 32, 33, 33]              64\n",
            "            Conv2d-5           [-1, 32, 33, 33]           9,216\n",
            "       BatchNorm2d-6           [-1, 32, 33, 33]              64\n",
            "            Conv2d-7           [-1, 32, 33, 33]           2,048\n",
            "       BatchNorm2d-8           [-1, 32, 33, 33]              64\n",
            "        BasicBlock-9           [-1, 32, 33, 33]               0\n",
            "           Conv2d-10           [-1, 32, 33, 33]           9,216\n",
            "      BatchNorm2d-11           [-1, 32, 33, 33]              64\n",
            "           Conv2d-12           [-1, 32, 33, 33]           9,216\n",
            "      BatchNorm2d-13           [-1, 32, 33, 33]              64\n",
            "       BasicBlock-14           [-1, 32, 33, 33]               0\n",
            "           Conv2d-15           [-1, 64, 17, 17]          18,432\n",
            "      BatchNorm2d-16           [-1, 64, 17, 17]             128\n",
            "           Conv2d-17           [-1, 64, 17, 17]          36,864\n",
            "      BatchNorm2d-18           [-1, 64, 17, 17]             128\n",
            "           Conv2d-19           [-1, 64, 17, 17]           2,048\n",
            "      BatchNorm2d-20           [-1, 64, 17, 17]             128\n",
            "       BasicBlock-21           [-1, 64, 17, 17]               0\n",
            "           Conv2d-22           [-1, 64, 17, 17]          36,864\n",
            "      BatchNorm2d-23           [-1, 64, 17, 17]             128\n",
            "           Conv2d-24           [-1, 64, 17, 17]          36,864\n",
            "      BatchNorm2d-25           [-1, 64, 17, 17]             128\n",
            "       BasicBlock-26           [-1, 64, 17, 17]               0\n",
            "           Conv2d-27            [-1, 128, 9, 9]          73,728\n",
            "      BatchNorm2d-28            [-1, 128, 9, 9]             256\n",
            "           Conv2d-29            [-1, 128, 9, 9]         147,456\n",
            "      BatchNorm2d-30            [-1, 128, 9, 9]             256\n",
            "           Conv2d-31            [-1, 128, 9, 9]           8,192\n",
            "      BatchNorm2d-32            [-1, 128, 9, 9]             256\n",
            "       BasicBlock-33            [-1, 128, 9, 9]               0\n",
            "           Conv2d-34            [-1, 128, 9, 9]         147,456\n",
            "      BatchNorm2d-35            [-1, 128, 9, 9]             256\n",
            "           Conv2d-36            [-1, 128, 9, 9]         147,456\n",
            "      BatchNorm2d-37            [-1, 128, 9, 9]             256\n",
            "       BasicBlock-38            [-1, 128, 9, 9]               0\n",
            "           Conv2d-39            [-1, 256, 5, 5]         294,912\n",
            "      BatchNorm2d-40            [-1, 256, 5, 5]             512\n",
            "           Conv2d-41            [-1, 256, 5, 5]         589,824\n",
            "      BatchNorm2d-42            [-1, 256, 5, 5]             512\n",
            "           Conv2d-43            [-1, 256, 5, 5]          32,768\n",
            "      BatchNorm2d-44            [-1, 256, 5, 5]             512\n",
            "       BasicBlock-45            [-1, 256, 5, 5]               0\n",
            "           Conv2d-46            [-1, 256, 5, 5]         589,824\n",
            "      BatchNorm2d-47            [-1, 256, 5, 5]             512\n",
            "           Conv2d-48            [-1, 256, 5, 5]         589,824\n",
            "      BatchNorm2d-49            [-1, 256, 5, 5]             512\n",
            "       BasicBlock-50            [-1, 256, 5, 5]               0\n",
            "           Linear-51                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 2,808,906\n",
            "Trainable params: 2,808,906\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 7.48\n",
            "Params size (MB): 10.72\n",
            "Estimated Total Size (MB): 18.21\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "# define data augmentation transforms\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std=[0.2023, 0.1994, 0.2010])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                         std=[0.2023, 0.1994, 0.2010])\n",
        "])\n",
        "\n",
        "# load CIFAR10 train and test datasets\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNhddq9qydzp",
        "outputId": "70e8fc69-acac-43ca-ed3f-ece9d744b6b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:12<00:00, 13170330.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "q_0B2EXcHtLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "vh7s569aIOnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=64"
      ],
      "metadata": {
        "id": "RFGmpx6wIjyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CZLMFvtIGDL",
        "outputId": "d1270326-56fa-49d8-eec8-c478b3bf3ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 30\n",
        "batch_size = 64\n",
        "learning_rate = 0.001\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "ufHK5LTPINcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        log_interval = 100\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item() * data.size(0)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQIxk11VIuXR",
        "outputId": "6602cde4-3e56-4f4c-8f17-e42e02588149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 0 [0/50000 (0%)]\tLoss: 2.462272\n",
            "Train Epoch: 0 [6400/50000 (13%)]\tLoss: 1.612968\n",
            "Train Epoch: 0 [12800/50000 (26%)]\tLoss: 1.730836\n",
            "Train Epoch: 0 [19200/50000 (38%)]\tLoss: 1.289715\n",
            "Train Epoch: 0 [25600/50000 (51%)]\tLoss: 1.301438\n",
            "Train Epoch: 0 [32000/50000 (64%)]\tLoss: 1.417357\n",
            "Train Epoch: 0 [38400/50000 (77%)]\tLoss: 1.369645\n",
            "Train Epoch: 0 [44800/50000 (90%)]\tLoss: 0.970528\n",
            "Test set: Average loss: 1.1074, Accuracy: 5980/10000 (60%)\n",
            "\n",
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 1.118584\n",
            "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 1.150240\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.179117\n",
            "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 1.100587\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.305598\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.001858\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.047647\n",
            "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 0.753472\n",
            "Test set: Average loss: 0.9739, Accuracy: 6547/10000 (65%)\n",
            "\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.786559\n",
            "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 0.807650\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.182511\n",
            "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.730760\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.802553\n",
            "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.710299\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.799468\n",
            "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.858407\n",
            "Test set: Average loss: 0.7306, Accuracy: 7457/10000 (75%)\n",
            "\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.507421\n",
            "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 0.773813\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.591328\n",
            "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.642397\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.489842\n",
            "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.471597\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.793923\n",
            "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 0.712106\n",
            "Test set: Average loss: 0.7275, Accuracy: 7506/10000 (75%)\n",
            "\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.307902\n",
            "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 0.664435\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.414370\n",
            "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 0.622957\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.606875\n",
            "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.510834\n",
            "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.497838\n",
            "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.633502\n",
            "Test set: Average loss: 0.6457, Accuracy: 7803/10000 (78%)\n",
            "\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.589798\n",
            "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 0.775130\n",
            "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.468931\n",
            "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 0.624033\n",
            "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.333363\n",
            "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.466844\n",
            "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.606757\n",
            "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 0.531661\n",
            "Test set: Average loss: 0.5694, Accuracy: 8045/10000 (80%)\n",
            "\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.459458\n",
            "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 0.568478\n",
            "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.450010\n",
            "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.441846\n",
            "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.506392\n",
            "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.335817\n",
            "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.261162\n",
            "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.664059\n",
            "Test set: Average loss: 0.5144, Accuracy: 8271/10000 (83%)\n",
            "\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.390620\n",
            "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.559231\n",
            "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.475674\n",
            "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.328007\n",
            "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.324120\n",
            "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.400823\n",
            "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.373112\n",
            "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.210075\n",
            "Test set: Average loss: 0.5637, Accuracy: 8063/10000 (81%)\n",
            "\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.452605\n",
            "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.292775\n",
            "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.266058\n",
            "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.342482\n",
            "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.494733\n",
            "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.342273\n",
            "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.477497\n",
            "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.279726\n",
            "Test set: Average loss: 0.4610, Accuracy: 8463/10000 (85%)\n",
            "\n",
            "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.349889\n",
            "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.355812\n",
            "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.312798\n",
            "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.316944\n",
            "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.417242\n",
            "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.348009\n",
            "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.571822\n",
            "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.318106\n",
            "Test set: Average loss: 0.4219, Accuracy: 8551/10000 (86%)\n",
            "\n",
            "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.254293\n",
            "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 0.590251\n",
            "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.262605\n",
            "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 0.320190\n",
            "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.154538\n",
            "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.320498\n",
            "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.327112\n",
            "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 0.144572\n",
            "Test set: Average loss: 0.4604, Accuracy: 8479/10000 (85%)\n",
            "\n",
            "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.493831\n",
            "Train Epoch: 11 [6400/50000 (13%)]\tLoss: 0.267273\n",
            "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.319644\n",
            "Train Epoch: 11 [19200/50000 (38%)]\tLoss: 0.189872\n",
            "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.372824\n",
            "Train Epoch: 11 [32000/50000 (64%)]\tLoss: 0.279351\n",
            "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.305217\n",
            "Train Epoch: 11 [44800/50000 (90%)]\tLoss: 0.265366\n",
            "Test set: Average loss: 0.4433, Accuracy: 8517/10000 (85%)\n",
            "\n",
            "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.199121\n",
            "Train Epoch: 12 [6400/50000 (13%)]\tLoss: 0.311892\n",
            "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.189405\n",
            "Train Epoch: 12 [19200/50000 (38%)]\tLoss: 0.198374\n",
            "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.396595\n",
            "Train Epoch: 12 [32000/50000 (64%)]\tLoss: 0.422459\n",
            "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.238514\n",
            "Train Epoch: 12 [44800/50000 (90%)]\tLoss: 0.321170\n",
            "Test set: Average loss: 0.4775, Accuracy: 8462/10000 (85%)\n",
            "\n",
            "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.169637\n",
            "Train Epoch: 13 [6400/50000 (13%)]\tLoss: 0.330556\n",
            "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.282444\n",
            "Train Epoch: 13 [19200/50000 (38%)]\tLoss: 0.406211\n",
            "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.351651\n",
            "Train Epoch: 13 [32000/50000 (64%)]\tLoss: 0.417764\n",
            "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.248677\n",
            "Train Epoch: 13 [44800/50000 (90%)]\tLoss: 0.182544\n",
            "Test set: Average loss: 0.4020, Accuracy: 8685/10000 (87%)\n",
            "\n",
            "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.359991\n",
            "Train Epoch: 14 [6400/50000 (13%)]\tLoss: 0.208370\n",
            "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.208347\n",
            "Train Epoch: 14 [19200/50000 (38%)]\tLoss: 0.349464\n",
            "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.326994\n",
            "Train Epoch: 14 [32000/50000 (64%)]\tLoss: 0.458224\n",
            "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.255392\n",
            "Train Epoch: 14 [44800/50000 (90%)]\tLoss: 0.276352\n",
            "Test set: Average loss: 0.3857, Accuracy: 8727/10000 (87%)\n",
            "\n",
            "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.269097\n",
            "Train Epoch: 15 [6400/50000 (13%)]\tLoss: 0.220605\n",
            "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.254195\n",
            "Train Epoch: 15 [19200/50000 (38%)]\tLoss: 0.170924\n",
            "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.153960\n",
            "Train Epoch: 15 [32000/50000 (64%)]\tLoss: 0.143381\n",
            "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 0.200605\n",
            "Train Epoch: 15 [44800/50000 (90%)]\tLoss: 0.455886\n",
            "Test set: Average loss: 0.3700, Accuracy: 8780/10000 (88%)\n",
            "\n",
            "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.290174\n",
            "Train Epoch: 16 [6400/50000 (13%)]\tLoss: 0.118165\n",
            "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 0.155784\n",
            "Train Epoch: 16 [19200/50000 (38%)]\tLoss: 0.175386\n",
            "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.235755\n",
            "Train Epoch: 16 [32000/50000 (64%)]\tLoss: 0.305282\n",
            "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 0.218829\n",
            "Train Epoch: 16 [44800/50000 (90%)]\tLoss: 0.226123\n",
            "Test set: Average loss: 0.4397, Accuracy: 8618/10000 (86%)\n",
            "\n",
            "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.227137\n",
            "Train Epoch: 17 [6400/50000 (13%)]\tLoss: 0.184307\n",
            "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 0.332681\n",
            "Train Epoch: 17 [19200/50000 (38%)]\tLoss: 0.208897\n",
            "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.159447\n",
            "Train Epoch: 17 [32000/50000 (64%)]\tLoss: 0.274572\n",
            "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.207376\n",
            "Train Epoch: 17 [44800/50000 (90%)]\tLoss: 0.269907\n",
            "Test set: Average loss: 0.4229, Accuracy: 8648/10000 (86%)\n",
            "\n",
            "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.178827\n",
            "Train Epoch: 18 [6400/50000 (13%)]\tLoss: 0.264234\n",
            "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 0.170932\n",
            "Train Epoch: 18 [19200/50000 (38%)]\tLoss: 0.139197\n",
            "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.175315\n",
            "Train Epoch: 18 [32000/50000 (64%)]\tLoss: 0.230141\n",
            "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 0.049988\n",
            "Train Epoch: 18 [44800/50000 (90%)]\tLoss: 0.264162\n",
            "Test set: Average loss: 0.3807, Accuracy: 8766/10000 (88%)\n",
            "\n",
            "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.144188\n",
            "Train Epoch: 19 [6400/50000 (13%)]\tLoss: 0.305865\n",
            "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 0.299666\n",
            "Train Epoch: 19 [19200/50000 (38%)]\tLoss: 0.201787\n",
            "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.190338\n",
            "Train Epoch: 19 [32000/50000 (64%)]\tLoss: 0.189767\n",
            "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.174828\n",
            "Train Epoch: 19 [44800/50000 (90%)]\tLoss: 0.171886\n",
            "Test set: Average loss: 0.3730, Accuracy: 8788/10000 (88%)\n",
            "\n",
            "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.120930\n",
            "Train Epoch: 20 [6400/50000 (13%)]\tLoss: 0.144227\n",
            "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 0.099169\n",
            "Train Epoch: 20 [19200/50000 (38%)]\tLoss: 0.051199\n",
            "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.191615\n",
            "Train Epoch: 20 [32000/50000 (64%)]\tLoss: 0.163065\n",
            "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 0.162283\n",
            "Train Epoch: 20 [44800/50000 (90%)]\tLoss: 0.101685\n",
            "Test set: Average loss: 0.3441, Accuracy: 8866/10000 (89%)\n",
            "\n",
            "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.241930\n",
            "Train Epoch: 21 [6400/50000 (13%)]\tLoss: 0.091271\n",
            "Train Epoch: 21 [12800/50000 (26%)]\tLoss: 0.133200\n",
            "Train Epoch: 21 [19200/50000 (38%)]\tLoss: 0.139044\n",
            "Train Epoch: 21 [25600/50000 (51%)]\tLoss: 0.209211\n",
            "Train Epoch: 21 [32000/50000 (64%)]\tLoss: 0.093611\n",
            "Train Epoch: 21 [38400/50000 (77%)]\tLoss: 0.245040\n",
            "Train Epoch: 21 [44800/50000 (90%)]\tLoss: 0.191457\n",
            "Test set: Average loss: 0.4071, Accuracy: 8708/10000 (87%)\n",
            "\n",
            "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.166330\n",
            "Train Epoch: 22 [6400/50000 (13%)]\tLoss: 0.102671\n",
            "Train Epoch: 22 [12800/50000 (26%)]\tLoss: 0.308864\n",
            "Train Epoch: 22 [19200/50000 (38%)]\tLoss: 0.131988\n",
            "Train Epoch: 22 [25600/50000 (51%)]\tLoss: 0.303820\n",
            "Train Epoch: 22 [32000/50000 (64%)]\tLoss: 0.156110\n",
            "Train Epoch: 22 [38400/50000 (77%)]\tLoss: 0.165043\n",
            "Train Epoch: 22 [44800/50000 (90%)]\tLoss: 0.130917\n",
            "Test set: Average loss: 0.3832, Accuracy: 8809/10000 (88%)\n",
            "\n",
            "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.052286\n",
            "Train Epoch: 23 [6400/50000 (13%)]\tLoss: 0.190035\n",
            "Train Epoch: 23 [12800/50000 (26%)]\tLoss: 0.222425\n",
            "Train Epoch: 23 [19200/50000 (38%)]\tLoss: 0.078738\n",
            "Train Epoch: 23 [25600/50000 (51%)]\tLoss: 0.060455\n",
            "Train Epoch: 23 [32000/50000 (64%)]\tLoss: 0.088441\n",
            "Train Epoch: 23 [38400/50000 (77%)]\tLoss: 0.144000\n",
            "Train Epoch: 23 [44800/50000 (90%)]\tLoss: 0.251397\n",
            "Test set: Average loss: 0.3652, Accuracy: 8881/10000 (89%)\n",
            "\n",
            "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.115527\n",
            "Train Epoch: 24 [6400/50000 (13%)]\tLoss: 0.172238\n",
            "Train Epoch: 24 [12800/50000 (26%)]\tLoss: 0.047842\n",
            "Train Epoch: 24 [19200/50000 (38%)]\tLoss: 0.129479\n",
            "Train Epoch: 24 [25600/50000 (51%)]\tLoss: 0.131174\n",
            "Train Epoch: 24 [32000/50000 (64%)]\tLoss: 0.179302\n",
            "Train Epoch: 24 [38400/50000 (77%)]\tLoss: 0.104501\n",
            "Train Epoch: 24 [44800/50000 (90%)]\tLoss: 0.295592\n",
            "Test set: Average loss: 0.3812, Accuracy: 8885/10000 (89%)\n",
            "\n",
            "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.126210\n",
            "Train Epoch: 25 [6400/50000 (13%)]\tLoss: 0.257167\n",
            "Train Epoch: 25 [12800/50000 (26%)]\tLoss: 0.087530\n",
            "Train Epoch: 25 [19200/50000 (38%)]\tLoss: 0.209011\n",
            "Train Epoch: 25 [25600/50000 (51%)]\tLoss: 0.181067\n",
            "Train Epoch: 25 [32000/50000 (64%)]\tLoss: 0.132631\n",
            "Train Epoch: 25 [38400/50000 (77%)]\tLoss: 0.140731\n",
            "Train Epoch: 25 [44800/50000 (90%)]\tLoss: 0.129396\n",
            "Test set: Average loss: 0.3819, Accuracy: 8881/10000 (89%)\n",
            "\n",
            "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.047014\n",
            "Train Epoch: 26 [6400/50000 (13%)]\tLoss: 0.192005\n",
            "Train Epoch: 26 [12800/50000 (26%)]\tLoss: 0.036636\n",
            "Train Epoch: 26 [19200/50000 (38%)]\tLoss: 0.130093\n",
            "Train Epoch: 26 [25600/50000 (51%)]\tLoss: 0.087660\n",
            "Train Epoch: 26 [32000/50000 (64%)]\tLoss: 0.164663\n",
            "Train Epoch: 26 [38400/50000 (77%)]\tLoss: 0.219092\n",
            "Train Epoch: 26 [44800/50000 (90%)]\tLoss: 0.069909\n",
            "Test set: Average loss: 0.3778, Accuracy: 8868/10000 (89%)\n",
            "\n",
            "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.089554\n",
            "Train Epoch: 27 [6400/50000 (13%)]\tLoss: 0.116204\n",
            "Train Epoch: 27 [12800/50000 (26%)]\tLoss: 0.071667\n",
            "Train Epoch: 27 [19200/50000 (38%)]\tLoss: 0.174573\n",
            "Train Epoch: 27 [25600/50000 (51%)]\tLoss: 0.162189\n",
            "Train Epoch: 27 [32000/50000 (64%)]\tLoss: 0.166080\n",
            "Train Epoch: 27 [38400/50000 (77%)]\tLoss: 0.233189\n",
            "Train Epoch: 27 [44800/50000 (90%)]\tLoss: 0.137307\n",
            "Test set: Average loss: 0.4459, Accuracy: 8713/10000 (87%)\n",
            "\n",
            "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.169919\n",
            "Train Epoch: 28 [6400/50000 (13%)]\tLoss: 0.047389\n",
            "Train Epoch: 28 [12800/50000 (26%)]\tLoss: 0.105768\n",
            "Train Epoch: 28 [19200/50000 (38%)]\tLoss: 0.138282\n",
            "Train Epoch: 28 [25600/50000 (51%)]\tLoss: 0.101206\n",
            "Train Epoch: 28 [32000/50000 (64%)]\tLoss: 0.201717\n",
            "Train Epoch: 28 [38400/50000 (77%)]\tLoss: 0.112004\n",
            "Train Epoch: 28 [44800/50000 (90%)]\tLoss: 0.069013\n",
            "Test set: Average loss: 0.3473, Accuracy: 8967/10000 (90%)\n",
            "\n",
            "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.137002\n",
            "Train Epoch: 29 [6400/50000 (13%)]\tLoss: 0.063647\n",
            "Train Epoch: 29 [12800/50000 (26%)]\tLoss: 0.220280\n",
            "Train Epoch: 29 [19200/50000 (38%)]\tLoss: 0.100720\n",
            "Train Epoch: 29 [25600/50000 (51%)]\tLoss: 0.043516\n",
            "Train Epoch: 29 [32000/50000 (64%)]\tLoss: 0.107391\n",
            "Train Epoch: 29 [38400/50000 (77%)]\tLoss: 0.104308\n",
            "Train Epoch: 29 [44800/50000 (90%)]\tLoss: 0.292259\n",
            "Test set: Average loss: 0.3746, Accuracy: 8905/10000 (89%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}